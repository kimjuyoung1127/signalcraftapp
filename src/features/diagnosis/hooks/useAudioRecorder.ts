import { useState, useEffect, useRef } from 'react';
import { Audio, InterruptionModeIOS, InterruptionModeAndroid } from 'expo-av';
import * as FileSystem from 'expo-file-system/legacy'; // ë³€ê²½ëœ ë¶€ë¶„
import { Platform } from 'react-native';

type RecordingStatus = 'idle' | 'recording' | 'paused' | 'stopped';

export const useAudioRecorder = () => {
  const [recording, setRecording] = useState<Audio.Recording | undefined>(undefined);
  const [status, setStatus] = useState<RecordingStatus>('idle');
  const [uri, setUri] = useState<string | undefined>(undefined);
  const [durationMillis, setDurationMillis] = useState<number>(0);

  // ê¶Œí•œ ìš”ì²­
  useEffect(() => {
    (async () => {
      const { status } = await Audio.requestPermissionsAsync();
      if (status !== 'granted') {
        console.warn("Microphone permission not granted.");
        // ì‚¬ìš©ìžì—ê²Œ ê¶Œí•œì´ í•„ìš”í•˜ë‹¤ê³  ì•Œë¦¼
      }
    })();
  }, []);

  const startRecording = async () => {
    try {
      // ë…¹ìŒ ì„¤ì •
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        staysActiveInBackground: false,
        interruptionModeIOS: InterruptionModeIOS.DoNotMix,
        interruptionModeAndroid: InterruptionModeAndroid.DoNotMix,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
      });

      const newRecording = new Audio.Recording();
      
      // ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± ì„¤ì • (500ms ë§ˆë‹¤ í˜¸ì¶œ)
      newRecording.setOnRecordingStatusUpdate((status) => {
        if (status.isRecording) {
          setDurationMillis(status.durationMillis);
        }
      });
      // [ê°œì„ ] í”Œëž«í¼ë³„ ê³ í’ˆì§ˆ ë…¹ìŒìœ¼ë¡œ ì„¤ì • ë³€ê²½
      await newRecording.prepareToRecordAsync({
        android: {
          // â­ Android: M4A AAC í¬ë§· (ì•ˆì •ì„± í™•ë³´)
          extension: '.m4a', 
          outputFormat: Audio.AndroidOutputFormat.MPEG_4,
          audioEncoder: Audio.AndroidAudioEncoder.AAC,
          sampleRate: 44100,        // [ë³€ê²½] ê³ í’ˆì§ˆ ìƒ˜í”Œë ˆì´íŠ¸ (22kHzê¹Œì§€ ë¶„ì„ ê°€ëŠ¥)
          numberOfChannels: 1,      // ëª¨ë…¸ (íŒŒì¼ í¬ê¸° íš¨ìœ¨í™”)
          bitRate: 128000,         // AAC ì••ì¶• í’ˆì§ˆ
          maxFileSize: 5000000,    // 5MB ì œí•œ
        },
        ios: {
          // â­ iOS: WAV ë¬´ì†ì‹¤ í¬ë§· (ìµœê³  í’ˆì§ˆ)
          extension: '.wav', 
          outputFormat: Audio.IOSOutputFormat.LINEARPCM,
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 44100,        // [ë³€ê²½] ê³ í’ˆì§ˆ ìƒ˜í”Œë ˆì´íŠ¸ (22kHzê¹Œì§€ ë¶„ì„ ê°€ëŠ¥)
          numberOfChannels: 1,      // ëª¨ë…¸
          bitRate: 1411,           // ë¬´ì†ì‹¤ PCM (16-bit)
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      });
      await newRecording.startAsync();

      setRecording(newRecording);
      setStatus('recording');
      setUri(undefined);
      setDurationMillis(0);

      // [ì¶”ê°€] í”Œëž«í¼ë³„ ë…¹ìŒ ì„¤ì • ë¡œê·¸
      console.log(`ðŸŽ¤ ë…¹ìŒ ì‹œìž‘ - Platform: ${Platform.OS}, Format: ${Platform.OS === 'ios' ? 'WAV (ë¬´ì†ì‹¤)' : 'M4A (AAC)'}`);
      
    } catch (err) {
      console.error('Failed to start recording', err);
      setStatus('idle');
    }
  };

  const stopRecording = async () => {
    try {
      if (recording) {
        await recording.stopAndUnloadAsync();
        const recordingUri = recording.getURI();
        setUri(recordingUri || undefined);
        setStatus('stopped');
        setRecording(undefined);
        console.log('Recording stopped and stored at', recordingUri);

        if (recordingUri) {
           const info = await FileSystem.getInfoAsync(recordingUri);
           console.log('Recording file info:', info);
        }
      }
    } catch (err) {
      console.error('Failed to stop recording', err);
      setStatus('stopped');
    }
  };

  const pauseRecording = async () => {
    try {
      if (recording && status === 'recording') {
        await recording.pauseAsync();
        setStatus('paused');
        console.log('Recording paused');
      }
    } catch (err) {
      console.error('Failed to pause recording', err);
    }
  };

  const resumeRecording = async () => {
    try {
      if (recording && status === 'paused') {
        await recording.startAsync();
        setStatus('recording');
        console.log('Recording resumed');
      }
    } catch (err) {
      console.error('Failed to resume recording', err);
    }
  };

  const resetRecorder = async () => {
      if (recording) {
          try {
              await recording.stopAndUnloadAsync();
          } catch (e) {
              console.warn("Error unloading recording during reset:", e);
          }
      }
      setRecording(undefined);
      setUri(undefined);
      setStatus('idle');
      setDurationMillis(0);
      console.log('Recorder reset to idle');
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë…¹ìŒ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (recording) {
        recording.stopAndUnloadAsync();
        setRecording(undefined);
      }
    };
  }, [recording]);

  return {
    recording,
    status,
    uri,
    durationMillis,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    resetRecorder, // ì¶”ê°€
  };
};

// í—¬í¼ í•¨ìˆ˜: ë°€ë¦¬ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
export const formatDuration = (millis: number) => {
  const totalSeconds = Math.floor(millis / 1000);
  const minutes = Math.floor(totalSeconds / 60);
  const seconds = totalSeconds % 60;
  return `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
};
